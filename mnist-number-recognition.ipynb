{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow as tf\nimport skimage","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:02:51.808137Z","iopub.execute_input":"2023-01-07T10:02:51.809010Z","iopub.status.idle":"2023-01-07T10:02:57.629144Z","shell.execute_reply.started":"2023-01-07T10:02:51.808964Z","shell.execute_reply":"2023-01-07T10:02:57.628126Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ntrain_data = np.genfromtxt('/kaggle/input/digit-recognizer/train.csv', delimiter=',')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:02:57.631474Z","iopub.execute_input":"2023-01-07T10:02:57.631977Z","iopub.status.idle":"2023-01-07T10:03:30.087622Z","shell.execute_reply.started":"2023-01-07T10:02:57.631929Z","shell.execute_reply":"2023-01-07T10:03:30.086294Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_labels = train_data[1:,0]\ntrain_data = train_data[1:,1:]","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:03:30.088909Z","iopub.execute_input":"2023-01-07T10:03:30.089250Z","iopub.status.idle":"2023-01-07T10:03:30.095241Z","shell.execute_reply.started":"2023-01-07T10:03:30.089219Z","shell.execute_reply":"2023-01-07T10:03:30.093732Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:03:30.098961Z","iopub.execute_input":"2023-01-07T10:03:30.099456Z","iopub.status.idle":"2023-01-07T10:03:30.108500Z","shell.execute_reply.started":"2023-01-07T10:03:30.099410Z","shell.execute_reply":"2023-01-07T10:03:30.107291Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(42000, 784)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = train_data.reshape(-1,28,28,1)\nprint(train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:03:30.110150Z","iopub.execute_input":"2023-01-07T10:03:30.110799Z","iopub.status.idle":"2023-01-07T10:03:30.119185Z","shell.execute_reply.started":"2023-01-07T10:03:30.110744Z","shell.execute_reply":"2023-01-07T10:03:30.117981Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(42000, 28, 28, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"training_array = keras.utils.to_categorical(train_labels, 10)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:03:30.121115Z","iopub.execute_input":"2023-01-07T10:03:30.121849Z","iopub.status.idle":"2023-01-07T10:03:31.229509Z","shell.execute_reply.started":"2023-01-07T10:03:30.121805Z","shell.execute_reply":"2023-01-07T10:03:31.228225Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(training_array.shape)\nprint(train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:03:31.230957Z","iopub.execute_input":"2023-01-07T10:03:31.231321Z","iopub.status.idle":"2023-01-07T10:03:31.240816Z","shell.execute_reply.started":"2023-01-07T10:03:31.231287Z","shell.execute_reply":"2023-01-07T10:03:31.239504Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(42000, 10)\n[1. 0. 1. ... 7. 6. 9.]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGen(keras.utils.Sequence):\n\n    def __init__(self, x_arr, y, batch_size):\n        self.x = x_arr\n        self.y = y\n        self.batch_size = batch_size\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n\n    def __getitem__(self, idx):\n        i = idx * self.batch_size\n        batch_imgs = self.x[i:i + self.batch_size,:,:]\n        batch_labs = self.y[i:i + self.batch_size,:]\n        im = np.zeros((self.batch_size,) + (28, 28) , dtype=\"float32\")\n        la = np.zeros((self.batch_size,10))\n        j = 0\n        for j in np.arange(batch_imgs.shape[0]):\n            img_array = np.squeeze(batch_imgs[j,:,:])\n            # Perform random data augmentation\n            rand_nums = np.random.rand(2,2)\n            if rand_nums[1,0]>0.5:\n                # rotate\n                if rand_nums[1,1]>0.5:\n                    img_array = skimage.transform.rotate(img_array, 10)\n                else:\n                    img_array = skimage.transform.rotate(img_array, 350)\n            # Perform min/max normalization\n            img_array = (img_array - np.min(img_array))/(np.max(img_array)-np.min(img_array))\n            #\n            im[j] = img_array\n            im = np.array(im)\n            la[j] = batch_labs[j,:]\n            la = np.array(la)\n        return im, la","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:19:55.212477Z","iopub.execute_input":"2023-01-07T10:19:55.212970Z","iopub.status.idle":"2023-01-07T10:19:55.225756Z","shell.execute_reply.started":"2023-01-07T10:19:55.212924Z","shell.execute_reply":"2023-01-07T10:19:55.224627Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"val_samples = int(np.floor(train_data.shape[0]*0.3))\n\ntrain_imgs = train_data[:-val_samples,:,:]\ntrain_labs = training_array[:-val_samples,:]\n\nval_imgs = train_data[-val_samples:,:,:]\nval_labs = training_array[-val_samples:,:]\n\ntrain_gen = DataGen(train_imgs, train_labs, 256)\nvalid_gen = DataGen(val_imgs, val_labs, 256)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:19:57.864143Z","iopub.execute_input":"2023-01-07T10:19:57.864579Z","iopub.status.idle":"2023-01-07T10:19:57.872503Z","shell.execute_reply.started":"2023-01-07T10:19:57.864541Z","shell.execute_reply":"2023-01-07T10:19:57.870910Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from keras import Input, layers, Model\n\ndef get_model(img_size):\n\n    inputs = Input(shape=img_size + (1,),dtype=tf.float16)\n    print(inputs.shape)\n\n    # [First half of the network: downsampling inputs]\n\n    # Entry block\n    e1 = layers.Conv2D(32, 3, strides=1, padding=\"same\", input_shape=(1, 28, 28, 1))(inputs)\n    e2 = layers.BatchNormalization()(e1)\n    e3 = layers.Activation(\"relu\")(e2)\n\n    e4 = layers.Conv2D(32,3, strides=1, padding='same')(e3)\n    e5 = layers.BatchNormalization()(e4)\n    e6 = layers.Activation(\"relu\")(e5)\n\n    pool_e = layers.MaxPool2D(pool_size=2, strides=2, padding='same')(e6)\n\n    #Down Block 1\n    db1conv1 = layers.Conv2D(64,3, strides=1, padding='same')(pool_e)\n    db1bn1 = layers.BatchNormalization()(db1conv1)\n    db1act1 = layers.Activation(\"relu\")(db1bn1)\n\n    db1conv2 = layers.Conv2D(64,3, strides=1, padding='same')(db1act1)\n    db1bn2 = layers.BatchNormalization()(db1conv2)\n    db1act2 = layers.Activation(\"relu\")(db1bn2)\n\n    pool_1 = layers.MaxPool2D(pool_size=2, strides=2, padding='same')(db1act2)\n\n    #Down Block 2\n    db2conv1 = layers.Conv2D(128,3, strides=1, padding='same')(pool_1)\n    db2bn1 = layers.BatchNormalization()(db2conv1)\n    db2act1 = layers.Activation(\"relu\")(db2bn1)\n\n    db2conv2 = layers.Conv2D(128,3, strides=1, padding='same')(db2act1)\n    db2bn2 = layers.BatchNormalization()(db2conv2)\n    db2act2 = layers.Activation(\"relu\")(db2bn2)\n\n\n\n    #Upsampling Block 1\n    up1up = layers.UpSampling2D(size=2)(db2act2)\n\n    up1conc = layers.concatenate([up1up, db1act2], axis=-1)\n\n    up1conv1 = layers.Conv2D(64,3,strides=1, padding=\"same\")(up1conc)\n    up1bn1 = layers.BatchNormalization()(up1conv1)\n    up1act1 = layers.Activation(\"relu\")(up1bn1)\n\n    up1conv2 = layers.Conv2D(64,3,strides=1, padding=\"same\")(up1act1)\n    up1bn2 = layers.BatchNormalization()(up1conv2)\n    up1act2 = layers.Activation(\"relu\")(up1bn2)\n\n    #Upsampling Block 0\n    up0up = layers.UpSampling2D(size=2)(up1act2)\n\n    up0conc = layers.concatenate([up0up, e6], axis=-1)\n\n    up0conv1 = layers.Conv2D(32,3,strides=1, padding=\"same\")(up0conc)\n    up0bn1 = layers.BatchNormalization()(up0conv1)\n    up0act1 = layers.Activation(\"relu\")(up0bn1)\n\n    up0conv2 = layers.Conv2D(32,3,strides=1, padding=\"same\")(up0act1)\n    up0bn2 = layers.BatchNormalization()(up0conv2)\n    up0act2 = layers.Activation(\"relu\")(up0bn2)\n\n    # Exit Layer\n    econv = layers.Conv2D(1, 1, data_format=\"channels_last\")(up0act2)\n    \n    flat = keras.layers.Flatten()(econv)\n    outputs = keras.layers.Dense(10, activation='softmax')(flat)\n\n    model = Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:20:00.524118Z","iopub.execute_input":"2023-01-07T10:20:00.524503Z","iopub.status.idle":"2023-01-07T10:20:00.545531Z","shell.execute_reply.started":"2023-01-07T10:20:00.524473Z","shell.execute_reply":"2023-01-07T10:20:00.543903Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = get_model((28,28))\na=model.summary(line_length=150)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:20:04.356143Z","iopub.execute_input":"2023-01-07T10:20:04.356603Z","iopub.status.idle":"2023-01-07T10:20:04.659368Z","shell.execute_reply.started":"2023-01-07T10:20:04.356559Z","shell.execute_reply":"2023-01-07T10:20:04.658241Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(None, 28, 28, 1)\nModel: \"model_1\"\n______________________________________________________________________________________________________________________________________________________\nLayer (type)                                     Output Shape                     Param #           Connected to                                      \n======================================================================================================================================================\ninput_2 (InputLayer)                             [(None, 28, 28, 1)]              0                                                                   \n______________________________________________________________________________________________________________________________________________________\nconv2d_11 (Conv2D)                               (None, 28, 28, 32)               320               input_2[0][0]                                     \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_10 (BatchNormalization)      (None, 28, 28, 32)               128               conv2d_11[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_10 (Activation)                       (None, 28, 28, 32)               0                 batch_normalization_10[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_12 (Conv2D)                               (None, 28, 28, 32)               9248              activation_10[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_11 (BatchNormalization)      (None, 28, 28, 32)               128               conv2d_12[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_11 (Activation)                       (None, 28, 28, 32)               0                 batch_normalization_11[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)                   (None, 14, 14, 32)               0                 activation_11[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconv2d_13 (Conv2D)                               (None, 14, 14, 64)               18496             max_pooling2d_2[0][0]                             \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_12 (BatchNormalization)      (None, 14, 14, 64)               256               conv2d_13[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_12 (Activation)                       (None, 14, 14, 64)               0                 batch_normalization_12[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_14 (Conv2D)                               (None, 14, 14, 64)               36928             activation_12[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_13 (BatchNormalization)      (None, 14, 14, 64)               256               conv2d_14[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_13 (Activation)                       (None, 14, 14, 64)               0                 batch_normalization_13[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)                   (None, 7, 7, 64)                 0                 activation_13[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconv2d_15 (Conv2D)                               (None, 7, 7, 128)                73856             max_pooling2d_3[0][0]                             \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_14 (BatchNormalization)      (None, 7, 7, 128)                512               conv2d_15[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_14 (Activation)                       (None, 7, 7, 128)                0                 batch_normalization_14[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_16 (Conv2D)                               (None, 7, 7, 128)                147584            activation_14[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_15 (BatchNormalization)      (None, 7, 7, 128)                512               conv2d_16[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_15 (Activation)                       (None, 7, 7, 128)                0                 batch_normalization_15[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)                   (None, 14, 14, 128)              0                 activation_15[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconcatenate_2 (Concatenate)                      (None, 14, 14, 192)              0                 up_sampling2d_2[0][0]                             \n                                                                                                    activation_13[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconv2d_17 (Conv2D)                               (None, 14, 14, 64)               110656            concatenate_2[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_16 (BatchNormalization)      (None, 14, 14, 64)               256               conv2d_17[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_16 (Activation)                       (None, 14, 14, 64)               0                 batch_normalization_16[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_18 (Conv2D)                               (None, 14, 14, 64)               36928             activation_16[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_17 (BatchNormalization)      (None, 14, 14, 64)               256               conv2d_18[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_17 (Activation)                       (None, 14, 14, 64)               0                 batch_normalization_17[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)                   (None, 28, 28, 64)               0                 activation_17[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconcatenate_3 (Concatenate)                      (None, 28, 28, 96)               0                 up_sampling2d_3[0][0]                             \n                                                                                                    activation_11[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconv2d_19 (Conv2D)                               (None, 28, 28, 32)               27680             concatenate_3[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_18 (BatchNormalization)      (None, 28, 28, 32)               128               conv2d_19[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_18 (Activation)                       (None, 28, 28, 32)               0                 batch_normalization_18[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_20 (Conv2D)                               (None, 28, 28, 32)               9248              activation_18[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_19 (BatchNormalization)      (None, 28, 28, 32)               128               conv2d_20[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_19 (Activation)                       (None, 28, 28, 32)               0                 batch_normalization_19[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_21 (Conv2D)                               (None, 28, 28, 1)                33                activation_19[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nflatten_1 (Flatten)                              (None, 784)                      0                 conv2d_21[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\ndense_1 (Dense)                                  (None, 10)                       7850              flatten_1[0][0]                                   \n======================================================================================================================================================\nTotal params: 481,387\nTrainable params: 480,107\nNon-trainable params: 1,280\n______________________________________________________________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import time, math\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=0.01), loss=['categorical_crossentropy'],metrics = ['categorical_accuracy'])\nepochs = 100\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(patience=10, verbose=1),\n    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00000001, verbose=1),\n    keras.callbacks.ModelCheckpoint(\"test2\", verbose=1, save_best_only=True)\n]\nstart = time.time()\nhistory = model.fit(train_gen, epochs=epochs, validation_data=valid_gen, callbacks=callbacks,shuffle=True)\nend = time.time()\nprint('Training time: ', end-start)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T10:20:18.831261Z","iopub.execute_input":"2023-01-07T10:20:18.831794Z","iopub.status.idle":"2023-01-07T12:12:59.119917Z","shell.execute_reply.started":"2023-01-07T10:20:18.831740Z","shell.execute_reply":"2023-01-07T12:12:59.118692Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/100\n115/115 [==============================] - 186s 2s/step - loss: 0.4910 - categorical_accuracy: 0.8479 - val_loss: 2.3615 - val_categorical_accuracy: 0.1101\n\nEpoch 00001: val_loss improved from inf to 2.36150, saving model to test2\nEpoch 2/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0921 - categorical_accuracy: 0.9709 - val_loss: 3.7065 - val_categorical_accuracy: 0.1648\n\nEpoch 00002: val_loss did not improve from 2.36150\nEpoch 3/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0666 - categorical_accuracy: 0.9782 - val_loss: 1.5856 - val_categorical_accuracy: 0.5113\n\nEpoch 00003: val_loss improved from 2.36150 to 1.58560, saving model to test2\nEpoch 4/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0456 - categorical_accuracy: 0.9845 - val_loss: 0.2559 - val_categorical_accuracy: 0.9091\n\nEpoch 00004: val_loss improved from 1.58560 to 0.25589, saving model to test2\nEpoch 5/100\n115/115 [==============================] - 183s 2s/step - loss: 0.0356 - categorical_accuracy: 0.9874 - val_loss: 0.1194 - val_categorical_accuracy: 0.9450\n\nEpoch 00005: val_loss improved from 0.25589 to 0.11945, saving model to test2\nEpoch 6/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0293 - categorical_accuracy: 0.9890 - val_loss: 0.0593 - val_categorical_accuracy: 0.9666\n\nEpoch 00006: val_loss improved from 0.11945 to 0.05933, saving model to test2\nEpoch 7/100\n115/115 [==============================] - 183s 2s/step - loss: 0.0306 - categorical_accuracy: 0.9885 - val_loss: 0.1917 - val_categorical_accuracy: 0.9189\n\nEpoch 00007: val_loss did not improve from 0.05933\nEpoch 8/100\n115/115 [==============================] - 183s 2s/step - loss: 0.0329 - categorical_accuracy: 0.9879 - val_loss: 0.0571 - val_categorical_accuracy: 0.9660\n\nEpoch 00008: val_loss improved from 0.05933 to 0.05708, saving model to test2\nEpoch 9/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0236 - categorical_accuracy: 0.9911 - val_loss: 0.0874 - val_categorical_accuracy: 0.9585\n\nEpoch 00009: val_loss did not improve from 0.05708\nEpoch 10/100\n115/115 [==============================] - 183s 2s/step - loss: 0.0324 - categorical_accuracy: 0.9876 - val_loss: 0.0635 - val_categorical_accuracy: 0.9659\n\nEpoch 00010: val_loss did not improve from 0.05708\nEpoch 11/100\n115/115 [==============================] - 183s 2s/step - loss: 0.0264 - categorical_accuracy: 0.9900 - val_loss: 0.0546 - val_categorical_accuracy: 0.9689\n\nEpoch 00011: val_loss improved from 0.05708 to 0.05459, saving model to test2\nEpoch 12/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0334 - categorical_accuracy: 0.9878 - val_loss: 0.0620 - val_categorical_accuracy: 0.9683\n\nEpoch 00012: val_loss did not improve from 0.05459\nEpoch 13/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0214 - categorical_accuracy: 0.9918 - val_loss: 0.1017 - val_categorical_accuracy: 0.9690\n\nEpoch 00013: val_loss did not improve from 0.05459\nEpoch 14/100\n115/115 [==============================] - 183s 2s/step - loss: 0.0495 - categorical_accuracy: 0.9846 - val_loss: 0.1283 - val_categorical_accuracy: 0.9599\n\nEpoch 00014: val_loss did not improve from 0.05459\nEpoch 15/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0496 - categorical_accuracy: 0.9844 - val_loss: 0.2840 - val_categorical_accuracy: 0.9228\n\nEpoch 00015: val_loss did not improve from 0.05459\nEpoch 16/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0610 - categorical_accuracy: 0.9818 - val_loss: 0.1174 - val_categorical_accuracy: 0.9616\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\nEpoch 00016: val_loss did not improve from 0.05459\nEpoch 17/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0228 - categorical_accuracy: 0.9921 - val_loss: 0.0530 - val_categorical_accuracy: 0.9727\n\nEpoch 00017: val_loss improved from 0.05459 to 0.05296, saving model to test2\nEpoch 18/100\n115/115 [==============================] - 186s 2s/step - loss: 0.0173 - categorical_accuracy: 0.9937 - val_loss: 0.0491 - val_categorical_accuracy: 0.9727\n\nEpoch 00018: val_loss improved from 0.05296 to 0.04913, saving model to test2\nEpoch 19/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0158 - categorical_accuracy: 0.9937 - val_loss: 0.0430 - val_categorical_accuracy: 0.9743\n\nEpoch 00019: val_loss improved from 0.04913 to 0.04299, saving model to test2\nEpoch 20/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0134 - categorical_accuracy: 0.9952 - val_loss: 0.0431 - val_categorical_accuracy: 0.9737\n\nEpoch 00020: val_loss did not improve from 0.04299\nEpoch 21/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0121 - categorical_accuracy: 0.9948 - val_loss: 0.0414 - val_categorical_accuracy: 0.9741\n\nEpoch 00021: val_loss improved from 0.04299 to 0.04140, saving model to test2\nEpoch 22/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0103 - categorical_accuracy: 0.9957 - val_loss: 0.0430 - val_categorical_accuracy: 0.9737\n\nEpoch 00022: val_loss did not improve from 0.04140\nEpoch 23/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0092 - categorical_accuracy: 0.9976 - val_loss: 0.0412 - val_categorical_accuracy: 0.9737\n\nEpoch 00023: val_loss improved from 0.04140 to 0.04122, saving model to test2\nEpoch 24/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0085 - categorical_accuracy: 0.9962 - val_loss: 0.0458 - val_categorical_accuracy: 0.9734\n\nEpoch 00024: val_loss did not improve from 0.04122\nEpoch 25/100\n115/115 [==============================] - 183s 2s/step - loss: 0.0092 - categorical_accuracy: 0.9963 - val_loss: 0.0541 - val_categorical_accuracy: 0.9715\n\nEpoch 00025: val_loss did not improve from 0.04122\nEpoch 26/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0091 - categorical_accuracy: 0.9960 - val_loss: 0.0409 - val_categorical_accuracy: 0.9746\n\nEpoch 00026: val_loss improved from 0.04122 to 0.04088, saving model to test2\nEpoch 27/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0074 - categorical_accuracy: 0.9968 - val_loss: 0.0513 - val_categorical_accuracy: 0.9732\n\nEpoch 00027: val_loss did not improve from 0.04088\nEpoch 28/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0074 - categorical_accuracy: 0.9969 - val_loss: 0.0427 - val_categorical_accuracy: 0.9741\n\nEpoch 00028: val_loss did not improve from 0.04088\nEpoch 29/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0072 - categorical_accuracy: 0.9969 - val_loss: 0.0432 - val_categorical_accuracy: 0.9737\n\nEpoch 00029: val_loss did not improve from 0.04088\nEpoch 30/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0083 - categorical_accuracy: 0.9968 - val_loss: 0.0461 - val_categorical_accuracy: 0.9741\n\nEpoch 00030: val_loss did not improve from 0.04088\nEpoch 31/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0067 - categorical_accuracy: 0.9973 - val_loss: 0.0440 - val_categorical_accuracy: 0.9743\n\nEpoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n\nEpoch 00031: val_loss did not improve from 0.04088\nEpoch 32/100\n115/115 [==============================] - 185s 2s/step - loss: 0.0058 - categorical_accuracy: 0.9976 - val_loss: 0.0456 - val_categorical_accuracy: 0.9744\n\nEpoch 00032: val_loss did not improve from 0.04088\nEpoch 33/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0051 - categorical_accuracy: 0.9976 - val_loss: 0.0417 - val_categorical_accuracy: 0.9747\n\nEpoch 00033: val_loss did not improve from 0.04088\nEpoch 34/100\n115/115 [==============================] - 186s 2s/step - loss: 0.0051 - categorical_accuracy: 0.9977 - val_loss: 0.0452 - val_categorical_accuracy: 0.9750\n\nEpoch 00034: val_loss did not improve from 0.04088\nEpoch 35/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0052 - categorical_accuracy: 0.9976 - val_loss: 0.0430 - val_categorical_accuracy: 0.9748\n\nEpoch 00035: val_loss did not improve from 0.04088\nEpoch 36/100\n115/115 [==============================] - 184s 2s/step - loss: 0.0045 - categorical_accuracy: 0.9980 - val_loss: 0.0434 - val_categorical_accuracy: 0.9745\n\nEpoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n\nEpoch 00036: val_loss did not improve from 0.04088\nEpoch 00036: early stopping\nTraining time:  6760.268334150314\n","output_type":"stream"}]},{"cell_type":"code","source":"class TestGen(keras.utils.Sequence):\n\n    def __init__(self, x_arr, batch_size):\n        self.x = x_arr\n        self.batch_size = batch_size\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n\n    def __getitem__(self, idx):\n        i = idx * self.batch_size\n        batch_imgs = self.x[i:i + self.batch_size,:,:]\n        im = np.zeros((self.batch_size,) + (28, 28) , dtype=\"float32\")\n        la = np.zeros((self.batch_size,10))\n        j = 0\n        for j in np.arange(batch_imgs.shape[0]):\n            img_array = np.squeeze(batch_imgs[j,:,:])\n            # Perform min/max normalization\n            img_array = (img_array - np.min(img_array))/(np.max(img_array)-np.min(img_array))\n            #\n            im[j] = img_array\n            im = np.array(im)\n        return im","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:31:33.454473Z","iopub.execute_input":"2023-01-07T12:31:33.455089Z","iopub.status.idle":"2023-01-07T12:31:33.466489Z","shell.execute_reply.started":"2023-01-07T12:31:33.455039Z","shell.execute_reply":"2023-01-07T12:31:33.465052Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_data = np.genfromtxt('/kaggle/input/digit-recognizer/test.csv', delimiter=',')\ntest_data = test_data[1:,:]\ntest_data = test_data.reshape(-1,28,28)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:31:38.187045Z","iopub.execute_input":"2023-01-07T12:31:38.187594Z","iopub.status.idle":"2023-01-07T12:32:00.897819Z","shell.execute_reply.started":"2023-01-07T12:31:38.187547Z","shell.execute_reply":"2023-01-07T12:32:00.896429Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:32:00.900330Z","iopub.execute_input":"2023-01-07T12:32:00.901357Z","iopub.status.idle":"2023-01-07T12:32:00.907270Z","shell.execute_reply.started":"2023-01-07T12:32:00.901315Z","shell.execute_reply":"2023-01-07T12:32:00.905857Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"(28000, 28, 28)\n","output_type":"stream"}]},{"cell_type":"code","source":"test_gen = TestGen(test_data, 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:32:00.909373Z","iopub.execute_input":"2023-01-07T12:32:00.909835Z","iopub.status.idle":"2023-01-07T12:32:00.918138Z","shell.execute_reply.started":"2023-01-07T12:32:00.909791Z","shell.execute_reply":"2023-01-07T12:32:00.916625Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_gen)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:32:08.629233Z","iopub.execute_input":"2023-01-07T12:32:08.629652Z","iopub.status.idle":"2023-01-07T12:35:32.542716Z","shell.execute_reply.started":"2023-01-07T12:32:08.629618Z","shell.execute_reply":"2023-01-07T12:35:32.541330Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(preds.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:35:32.548419Z","iopub.execute_input":"2023-01-07T12:35:32.549105Z","iopub.status.idle":"2023-01-07T12:35:32.555953Z","shell.execute_reply.started":"2023-01-07T12:35:32.549064Z","shell.execute_reply":"2023-01-07T12:35:32.554307Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"(28000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.argmax(preds, -1)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:35:32.557420Z","iopub.execute_input":"2023-01-07T12:35:32.557899Z","iopub.status.idle":"2023-01-07T12:35:32.567514Z","shell.execute_reply.started":"2023-01-07T12:35:32.557856Z","shell.execute_reply":"2023-01-07T12:35:32.566158Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(preds.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:41:00.644099Z","iopub.execute_input":"2023-01-07T12:41:00.644591Z","iopub.status.idle":"2023-01-07T12:41:00.650960Z","shell.execute_reply.started":"2023-01-07T12:41:00.644551Z","shell.execute_reply":"2023-01-07T12:41:00.649831Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"(28000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame(\n    {\n        'ImageId': np.arange(1, preds.shape[0]+1),\n        'Label': preds\n    }\n)\nsubmission.to_csv('/kaggle/working/submission_2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T12:41:15.204817Z","iopub.execute_input":"2023-01-07T12:41:15.205278Z","iopub.status.idle":"2023-01-07T12:41:15.243645Z","shell.execute_reply.started":"2023-01-07T12:41:15.205243Z","shell.execute_reply":"2023-01-07T12:41:15.242667Z"},"trusted":true},"execution_count":30,"outputs":[]}]}