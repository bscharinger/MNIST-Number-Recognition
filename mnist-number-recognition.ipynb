{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow as tf\nimport skimage","metadata":{"execution":{"iopub.status.busy":"2023-01-05T20:45:34.162418Z","iopub.execute_input":"2023-01-05T20:45:34.162828Z","iopub.status.idle":"2023-01-05T20:45:38.823494Z","shell.execute_reply.started":"2023-01-05T20:45:34.162794Z","shell.execute_reply":"2023-01-05T20:45:38.822245Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ntrain_data = np.genfromtxt('/kaggle/input/digit-recognizer/train.csv', delimiter=',')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T20:48:41.302385Z","iopub.execute_input":"2023-01-05T20:48:41.303142Z","iopub.status.idle":"2023-01-05T20:49:12.107254Z","shell.execute_reply.started":"2023-01-05T20:48:41.303110Z","shell.execute_reply":"2023-01-05T20:49:12.106268Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_labels = train_data[1:,0]\ntrain_data = train_data[1:,1:]","metadata":{"execution":{"iopub.status.busy":"2023-01-05T20:49:17.658154Z","iopub.execute_input":"2023-01-05T20:49:17.658522Z","iopub.status.idle":"2023-01-05T20:49:17.664945Z","shell.execute_reply.started":"2023-01-05T20:49:17.658494Z","shell.execute_reply":"2023-01-05T20:49:17.664116Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T20:49:19.814282Z","iopub.execute_input":"2023-01-05T20:49:19.815331Z","iopub.status.idle":"2023-01-05T20:49:19.820794Z","shell.execute_reply.started":"2023-01-05T20:49:19.815284Z","shell.execute_reply":"2023-01-05T20:49:19.819649Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(42000, 784)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = train_data.reshape(-1,28,28,1)\nprint(train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T20:49:26.419010Z","iopub.execute_input":"2023-01-05T20:49:26.419404Z","iopub.status.idle":"2023-01-05T20:49:26.426456Z","shell.execute_reply.started":"2023-01-05T20:49:26.419374Z","shell.execute_reply":"2023-01-05T20:49:26.425081Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(42000, 28, 28, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"training_array = keras.utils.to_categorical(train_labels, 10)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T21:09:14.490959Z","iopub.execute_input":"2023-01-05T21:09:14.492191Z","iopub.status.idle":"2023-01-05T21:09:14.498414Z","shell.execute_reply.started":"2023-01-05T21:09:14.492144Z","shell.execute_reply":"2023-01-05T21:09:14.497203Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(training_array.shape)\nprint(train_labels)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T21:10:05.074308Z","iopub.execute_input":"2023-01-05T21:10:05.074718Z","iopub.status.idle":"2023-01-05T21:10:05.080473Z","shell.execute_reply.started":"2023-01-05T21:10:05.074657Z","shell.execute_reply":"2023-01-05T21:10:05.079602Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"(42000, 10)\n[1. 0. 1. ... 7. 6. 9.]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGen(keras.utils.Sequence):\n\n    def __init__(self, x_arr, y, batch_size):\n        self.x = x_arr\n        self.y = y\n        self.batch_size = batch_size\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n\n    def __getitem__(self, idx):\n        i = idx * self.batch_size\n        batch_imgs = self.x[i:i + self.batch_size,:,:]\n        batch_labs = self.y[i:i + self.batch_size,:]\n        im = np.zeros((self.batch_size,) + (28, 28) , dtype=\"float32\")\n        la = np.zeros((self.batch_size,10))\n        j = 0\n        for j in np.arange(batch_imgs.shape[0]):\n            img_array = np.squeeze(batch_imgs[j,:,:])\n            # Perform random data augmentation\n            rand_nums = np.random.rand(2,2)\n            if rand_nums[0,0]>0.5:\n                # flip\n                if rand_nums[0,1]>0.5:\n                    img_array = np.fliplr(img_array)\n                else:\n                    img_array = np.flipud(img_array)\n            if rand_nums[1,0]>0.5:\n                # rotate\n                if rand_nums[1,1]>0.5:\n                    img_array = skimage.transform.rotate(img_array, 30)\n                else:\n                    img_array = skimage.transform.rotate(img_array, 330)\n            # Perform min/max normalization\n            img_array = (img_array - np.min(img_array))/(np.max(img_array)-np.min(img_array))\n            #\n            im[j] = img_array\n            im = np.array(im)\n            la[j] = batch_labs[j,:]\n            la = np.array(la)\n        return im, la","metadata":{"execution":{"iopub.status.busy":"2023-01-05T21:28:44.576347Z","iopub.execute_input":"2023-01-05T21:28:44.576756Z","iopub.status.idle":"2023-01-05T21:28:44.593009Z","shell.execute_reply.started":"2023-01-05T21:28:44.576723Z","shell.execute_reply":"2023-01-05T21:28:44.591664Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"val_samples = int(np.floor(train_data.shape[0]*0.3))\n\ntrain_imgs = train_data[:-val_samples,:,:]\ntrain_labs = training_array[:-val_samples,:]\n\nval_imgs = train_data[-val_samples:,:,:]\nval_labs = training_array[-val_samples:,:]\n\ntrain_gen = DataGen(train_imgs, train_labs, 64)\nvalid_gen = DataGen(val_imgs, val_labs, 64)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T21:28:49.347197Z","iopub.execute_input":"2023-01-05T21:28:49.347636Z","iopub.status.idle":"2023-01-05T21:28:49.354622Z","shell.execute_reply.started":"2023-01-05T21:28:49.347600Z","shell.execute_reply":"2023-01-05T21:28:49.353482Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from keras import Input, layers, Model\n\ndef get_model(img_size):\n\n    inputs = Input(shape=img_size + (1,),dtype=tf.float16)\n    print(inputs.shape)\n\n    # [First half of the network: downsampling inputs]\n\n    # Entry block\n    e1 = layers.Conv2D(16, 3, strides=1, padding=\"same\", input_shape=(1, 28, 28, 1))(inputs)\n    e2 = layers.BatchNormalization()(e1)\n    e3 = layers.Activation(\"relu\")(e2)\n\n    e4 = layers.Conv2D(16,3, strides=1, padding='same')(e3)\n    e5 = layers.BatchNormalization()(e4)\n    e6 = layers.Activation(\"relu\")(e5)\n\n    pool_e = layers.MaxPool2D(pool_size=2, strides=2, padding='same')(e6)\n\n    #Down Block 1\n    db1conv1 = layers.Conv2D(32,3, strides=1, padding='same')(pool_e)\n    db1bn1 = layers.BatchNormalization()(db1conv1)\n    db1act1 = layers.Activation(\"relu\")(db1bn1)\n\n    db1conv2 = layers.Conv2D(32,3, strides=1, padding='same')(db1act1)\n    db1bn2 = layers.BatchNormalization()(db1conv2)\n    db1act2 = layers.Activation(\"relu\")(db1bn2)\n\n    pool_1 = layers.MaxPool2D(pool_size=2, strides=2, padding='same')(db1act2)\n\n    #Down Block 2\n    db2conv1 = layers.Conv2D(64,3, strides=1, padding='same')(pool_1)\n    db2bn1 = layers.BatchNormalization()(db2conv1)\n    db2act1 = layers.Activation(\"relu\")(db2bn1)\n\n    db2conv2 = layers.Conv2D(64,3, strides=1, padding='same')(db2act1)\n    db2bn2 = layers.BatchNormalization()(db2conv2)\n    db2act2 = layers.Activation(\"relu\")(db2bn2)\n\n\n\n    #Upsampling Block 1\n    up1up = layers.UpSampling2D(size=2)(db2act2)\n\n    up1conc = layers.concatenate([up1up, db1act2], axis=-1)\n\n    up1conv1 = layers.Conv2D(32,3,strides=1, padding=\"same\")(up1conc)\n    up1bn1 = layers.BatchNormalization()(up1conv1)\n    up1act1 = layers.Activation(\"relu\")(up1bn1)\n\n    up1conv2 = layers.Conv2D(32,3,strides=1, padding=\"same\")(up1act1)\n    up1bn2 = layers.BatchNormalization()(up1conv2)\n    up1act2 = layers.Activation(\"relu\")(up1bn2)\n\n    #Upsampling Block 0\n    up0up = layers.UpSampling2D(size=2)(up1act2)\n\n    up0conc = layers.concatenate([up0up, e6], axis=-1)\n\n    up0conv1 = layers.Conv2D(16,3,strides=1, padding=\"same\")(up0conc)\n    up0bn1 = layers.BatchNormalization()(up0conv1)\n    up0act1 = layers.Activation(\"relu\")(up0bn1)\n\n    up0conv2 = layers.Conv2D(16,3,strides=1, padding=\"same\")(up0act1)\n    up0bn2 = layers.BatchNormalization()(up0conv2)\n    up0act2 = layers.Activation(\"relu\")(up0bn2)\n\n    # Exit Layer\n    econv = layers.Conv2D(1, 1, data_format=\"channels_last\")(up0act2)\n    \n    flat = keras.layers.Flatten()(econv)\n    outputs = keras.layers.Dense(10, activation='softmax')(flat)\n\n    model = Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-05T21:17:37.189891Z","iopub.execute_input":"2023-01-05T21:17:37.190336Z","iopub.status.idle":"2023-01-05T21:17:37.209063Z","shell.execute_reply.started":"2023-01-05T21:17:37.190301Z","shell.execute_reply":"2023-01-05T21:17:37.207886Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model = get_model((28,28))\na=model.summary(line_length=150)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T21:17:40.808082Z","iopub.execute_input":"2023-01-05T21:17:40.808494Z","iopub.status.idle":"2023-01-05T21:17:41.306940Z","shell.execute_reply.started":"2023-01-05T21:17:40.808460Z","shell.execute_reply":"2023-01-05T21:17:41.305749Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(None, 28, 28, 1)\nModel: \"model_1\"\n______________________________________________________________________________________________________________________________________________________\nLayer (type)                                     Output Shape                     Param #           Connected to                                      \n======================================================================================================================================================\ninput_7 (InputLayer)                             [(None, 28, 28, 1)]              0                                                                   \n______________________________________________________________________________________________________________________________________________________\nconv2d_31 (Conv2D)                               (None, 28, 28, 16)               160               input_7[0][0]                                     \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_35 (BatchNormalization)      (None, 28, 28, 16)               64                conv2d_31[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_36 (Activation)                       (None, 28, 28, 16)               0                 batch_normalization_35[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_32 (Conv2D)                               (None, 28, 28, 16)               2320              activation_36[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_36 (BatchNormalization)      (None, 28, 28, 16)               64                conv2d_32[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_37 (Activation)                       (None, 28, 28, 16)               0                 batch_normalization_36[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nmax_pooling2d_9 (MaxPooling2D)                   (None, 14, 14, 16)               0                 activation_37[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconv2d_33 (Conv2D)                               (None, 14, 14, 32)               4640              max_pooling2d_9[0][0]                             \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_37 (BatchNormalization)      (None, 14, 14, 32)               128               conv2d_33[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_38 (Activation)                       (None, 14, 14, 32)               0                 batch_normalization_37[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_34 (Conv2D)                               (None, 14, 14, 32)               9248              activation_38[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_38 (BatchNormalization)      (None, 14, 14, 32)               128               conv2d_34[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_39 (Activation)                       (None, 14, 14, 32)               0                 batch_normalization_38[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nmax_pooling2d_10 (MaxPooling2D)                  (None, 7, 7, 32)                 0                 activation_39[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconv2d_35 (Conv2D)                               (None, 7, 7, 64)                 18496             max_pooling2d_10[0][0]                            \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_39 (BatchNormalization)      (None, 7, 7, 64)                 256               conv2d_35[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_40 (Activation)                       (None, 7, 7, 64)                 0                 batch_normalization_39[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_36 (Conv2D)                               (None, 7, 7, 64)                 36928             activation_40[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_40 (BatchNormalization)      (None, 7, 7, 64)                 256               conv2d_36[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_41 (Activation)                       (None, 7, 7, 64)                 0                 batch_normalization_40[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nup_sampling2d_5 (UpSampling2D)                   (None, 14, 14, 64)               0                 activation_41[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconcatenate_5 (Concatenate)                      (None, 14, 14, 96)               0                 up_sampling2d_5[0][0]                             \n                                                                                                    activation_39[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconv2d_37 (Conv2D)                               (None, 14, 14, 32)               27680             concatenate_5[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_41 (BatchNormalization)      (None, 14, 14, 32)               128               conv2d_37[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_42 (Activation)                       (None, 14, 14, 32)               0                 batch_normalization_41[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_38 (Conv2D)                               (None, 14, 14, 32)               9248              activation_42[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_42 (BatchNormalization)      (None, 14, 14, 32)               128               conv2d_38[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_43 (Activation)                       (None, 14, 14, 32)               0                 batch_normalization_42[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nup_sampling2d_6 (UpSampling2D)                   (None, 28, 28, 32)               0                 activation_43[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconcatenate_6 (Concatenate)                      (None, 28, 28, 48)               0                 up_sampling2d_6[0][0]                             \n                                                                                                    activation_37[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nconv2d_39 (Conv2D)                               (None, 28, 28, 16)               6928              concatenate_6[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_43 (BatchNormalization)      (None, 28, 28, 16)               64                conv2d_39[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_44 (Activation)                       (None, 28, 28, 16)               0                 batch_normalization_43[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_40 (Conv2D)                               (None, 28, 28, 16)               2320              activation_44[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nbatch_normalization_44 (BatchNormalization)      (None, 28, 28, 16)               64                conv2d_40[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\nactivation_45 (Activation)                       (None, 28, 28, 16)               0                 batch_normalization_44[0][0]                      \n______________________________________________________________________________________________________________________________________________________\nconv2d_41 (Conv2D)                               (None, 28, 28, 1)                17                activation_45[0][0]                               \n______________________________________________________________________________________________________________________________________________________\nflatten (Flatten)                                (None, 784)                      0                 conv2d_41[0][0]                                   \n______________________________________________________________________________________________________________________________________________________\ndense (Dense)                                    (None, 10)                       7850              flatten[0][0]                                     \n======================================================================================================================================================\nTotal params: 127,115\nTrainable params: 126,475\nNon-trainable params: 640\n______________________________________________________________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import time, math\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=0.01), loss=['categorical_crossentropy'],metrics = ['categorical_accuracy'])\nepochs = 300\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(patience=20, verbose=1),\n    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00000001, verbose=1),\n    keras.callbacks.ModelCheckpoint(\"test1\", verbose=1, save_best_only=True)\n]\nstart = time.time()\nhistory = model.fit(train_gen, epochs=epochs, validation_data=valid_gen, callbacks=callbacks,shuffle=True)\nend = time.time()\nprint('Training time: ', end-start)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T21:28:53.680740Z","iopub.execute_input":"2023-01-05T21:28:53.681102Z","iopub.status.idle":"2023-01-05T21:44:42.328392Z","shell.execute_reply.started":"2023-01-05T21:28:53.681073Z","shell.execute_reply":"2023-01-05T21:44:42.327037Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"2023-01-05 21:28:54.035208: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/300\n460/460 [==============================] - 73s 155ms/step - loss: 0.8333 - categorical_accuracy: 0.7216 - val_loss: 0.8744 - val_categorical_accuracy: 0.6973\n\nEpoch 00001: val_loss improved from inf to 0.87445, saving model to test1\n","output_type":"stream"},{"name":"stderr","text":"2023-01-05 21:30:09.406278: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/300\n460/460 [==============================] - 72s 157ms/step - loss: 0.3421 - categorical_accuracy: 0.8882 - val_loss: 0.3251 - val_categorical_accuracy: 0.8952\n\nEpoch 00002: val_loss improved from 0.87445 to 0.32509, saving model to test1\nEpoch 3/300\n460/460 [==============================] - 70s 153ms/step - loss: 0.2634 - categorical_accuracy: 0.9155 - val_loss: 0.3524 - val_categorical_accuracy: 0.8870\n\nEpoch 00003: val_loss did not improve from 0.32509\nEpoch 4/300\n460/460 [==============================] - 71s 154ms/step - loss: 0.2156 - categorical_accuracy: 0.9303 - val_loss: 0.2249 - val_categorical_accuracy: 0.9293\n\nEpoch 00004: val_loss improved from 0.32509 to 0.22493, saving model to test1\nEpoch 5/300\n460/460 [==============================] - 69s 150ms/step - loss: 0.1925 - categorical_accuracy: 0.9380 - val_loss: 0.1810 - val_categorical_accuracy: 0.9455\n\nEpoch 00005: val_loss improved from 0.22493 to 0.18098, saving model to test1\nEpoch 6/300\n460/460 [==============================] - 69s 150ms/step - loss: 0.1673 - categorical_accuracy: 0.9440 - val_loss: 0.1858 - val_categorical_accuracy: 0.9392\n\nEpoch 00006: val_loss did not improve from 0.18098\nEpoch 7/300\n460/460 [==============================] - 69s 150ms/step - loss: 0.1517 - categorical_accuracy: 0.9512 - val_loss: 0.1728 - val_categorical_accuracy: 0.9419\n\nEpoch 00007: val_loss improved from 0.18098 to 0.17281, saving model to test1\nEpoch 8/300\n460/460 [==============================] - 70s 153ms/step - loss: 0.1397 - categorical_accuracy: 0.9542 - val_loss: 0.1497 - val_categorical_accuracy: 0.9519\n\nEpoch 00008: val_loss improved from 0.17281 to 0.14969, saving model to test1\nEpoch 9/300\n460/460 [==============================] - 72s 157ms/step - loss: 0.1306 - categorical_accuracy: 0.9571 - val_loss: 0.2076 - val_categorical_accuracy: 0.9357\n\nEpoch 00009: val_loss did not improve from 0.14969\nEpoch 10/300\n460/460 [==============================] - 73s 158ms/step - loss: 0.1270 - categorical_accuracy: 0.9581 - val_loss: 0.1530 - val_categorical_accuracy: 0.9519\n\nEpoch 00010: val_loss did not improve from 0.14969\nEpoch 11/300\n460/460 [==============================] - 72s 156ms/step - loss: 0.1190 - categorical_accuracy: 0.9598 - val_loss: 0.1258 - val_categorical_accuracy: 0.9593\n\nEpoch 00011: val_loss improved from 0.14969 to 0.12580, saving model to test1\nEpoch 12/300\n367/460 [======================>.......] - ETA: 12s - loss: 0.1130 - categorical_accuracy: 0.9623","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2890012429.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     10\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}